# üß† Introdu√ß√£o ao Processamento de Linguagem Natural (PLN)

Ol√°, seja bem-vindo(a)! üëã

Este material √© uma introdu√ß√£o pr√°tica e conceitual ao fascinante mundo do **Processamento de Linguagem Natural (PLN)**, tamb√©m conhecido como **NLP (Natural Language Processing)**. O foco √© mostrar como os computadores podem entender, interpretar e trabalhar com a linguagem humana, seja falada ou escrita.

## üìå Por que isso importa?

Vivemos cercados por tecnologias que dependem do PLN:

* Chatbots em sites de atendimento
* Assistentes virtuais
* Aplicativos de tradu√ß√£o
* Sistemas de busca por voz
* An√°lise de sentimentos e muito mais!

Essas aplica√ß√µes est√£o cada vez mais inteligentes, gra√ßas ao uso de **machine learning** e t√©cnicas de linguagem natural.

---

## üß© Conceitos Fundamentais

Durante o aprendizado, voc√™ ir√° entender conceitos essenciais como:

### üîπ Corpus

√â um conjunto de textos anotados manualmente que servem de base para o treinamento e valida√ß√£o de algoritmos de PLN.

### üîπ Tokeniza√ß√£o

√â o processo de dividir um texto em partes menores chamadas **tokens**, que geralmente s√£o palavras ou pontua√ß√µes.

### üîπ Stop Words

S√£o palavras que, por n√£o adicionarem muito significado (como ‚Äúo‚Äù, ‚Äúde‚Äù, ‚Äúa‚Äù), podem ser removidas para simplificar a an√°lise de texto.

---

## üõ†Ô∏è Colocando em pr√°tica com Python + NLTK

Utilizamos a biblioteca **NLTK (Natural Language Toolkit)** para aplicar esses conceitos na pr√°tica. Veja algumas etapas:

```python
!pip install nltk
import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords
stopwords = stopwords.words('portuguese')
```

### Exemplo de Tokeniza√ß√£o e remo√ß√£o de stop words:

```python
from nltk.tokenize import word_tokenize
nltk.download('punkt')

frase = 'Eu dirijo devagar porque n√≥s queremos ver os animais.'
tokens = word_tokenize(frase)

for t in tokens:
    if t.lower() not in stopwords:
        print(t)
```

Resultado: apenas palavras relevantes da frase s√£o exibidas.

---

## üìà TF-IDF: O que √© importante em um texto?

Outra t√©cnica essencial √© o c√°lculo **TF-IDF (Term Frequency - Inverse Document Frequency)**. Ele identifica quais palavras s√£o mais importantes em um documento, levando em conta:

* A frequ√™ncia com que aparecem em um √∫nico texto (**TF**)
* E em quantos textos elas aparecem (**IDF**)

### Exemplo pr√°tico com Scikit-learn:

```python
from sklearn.feature_extraction.text import TfidfVectorizer
import pandas as pd

texto1 = 'A matem√°tica √© muito importante para compreendermos como a natureza funciona'
texto2 = 'A matem√°tica √© incr√≠vel, quanto mais estudo matem√°tica, mais eu consigo aprender matem√°tica'

tfidf = TfidfVectorizer()
vetor = tfidf.fit_transform([texto1, texto2]).todense()
nomes = tfidf.get_feature_names_out()

df = pd.DataFrame(vetor, columns=nomes)
print(df)
```

Esse c√≥digo cria um DataFrame com os pesos de cada palavra, mostrando quais termos se destacam em cada texto. Por exemplo, ‚Äúmatem√°tica‚Äù recebe maior peso no segundo texto por se repetir v√°rias vezes.

---