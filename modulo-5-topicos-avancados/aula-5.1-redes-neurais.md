# ğŸ¤– IntroduÃ§Ã£o Ã  InteligÃªncia Artificial: K-means, NeurÃ´nios Artificiais e Redes Neurais

Bem-vindo(a)! Nesta aula, vocÃª deu um grande passo na jornada do aprendizado de **Machine Learning** e **Redes Neurais**, explorando desde mÃ©todos de agrupamento atÃ© a estrutura bÃ¡sica de como uma rede neural funciona por dentro. Vamos recapitular de forma leve e didÃ¡tica o que foi abordado:

---

## ğŸ¯ Parte 1: ClusterizaÃ§Ã£o com K-means

VocÃª aprendeu sobre o **K-means**, um dos algoritmos de **aprendizado nÃ£o supervisionado** mais populares. Ele Ã© usado para **agrupar dados** com caracterÃ­sticas semelhantes, sem a necessidade de rÃ³tulos.

### ğŸ§  Como funciona?

* Escolhe-se um nÃºmero de grupos (k).
* O algoritmo posiciona k centrÃ³ides.
* Cada ponto Ã© atribuÃ­do ao centrÃ³ide mais prÃ³ximo.
* Os centrÃ³ides sÃ£o atualizados com base na mÃ©dia dos pontos atribuÃ­dos.
* O processo se repete atÃ© os grupos estabilizarem.

### ğŸ› ï¸ AplicaÃ§Ã£o prÃ¡tica:

VocÃª utilizou o K-means para agrupar **clientes de um shopping** com base em **renda anual** e **score de consumo**. Descobriu como o algoritmo pode ajudar empresas a entenderem melhor seu pÃºblico-alvo.

---

## ğŸ§© Parte 2: O NeurÃ´nio Artificial (McCulloch-Pitts)

Em seguida, vocÃª mergulhou na base da **rede neural artificial**, conhecendo o **modelo de McCulloch-Pitts**.

### ğŸ” O que Ã©?

* Um modelo matemÃ¡tico simples inspirado nos neurÃ´nios biolÃ³gicos.
* Possui **entradas binÃ¡rias** (0 ou 1).
* Realiza um **somatÃ³rio** dessas entradas.
* Compara o resultado a um **limiar**. Se ultrapassar, o neurÃ´nio â€œdisparaâ€ (saÃ­da = 1), caso contrÃ¡rio, nÃ£o (saÃ­da = 0).

Este modelo Ã© **a base para redes mais complexas**, por ser simples e eficiente.

---

## âš™ï¸ Parte 3: O Perceptron e FunÃ§Ãµes de AtivaÃ§Ã£o

VocÃª conheceu o **Perceptron**, uma evoluÃ§Ã£o do neurÃ´nio de McCulloch-Pitts, que adiciona **pesos** Ã s entradas, permitindo que cada entrada tenha importÃ¢ncia diferente.

### ğŸ’¡ ImportÃ¢ncia dos Pesos

* Cada entrada Ã© multiplicada por um peso.
* Isso permite controlar a **sensibilidade do neurÃ´nio** a cada tipo de informaÃ§Ã£o.

### âš¡ FunÃ§Ãµes de AtivaÃ§Ã£o

ApÃ³s o somatÃ³rio ponderado, uma **funÃ§Ã£o de ativaÃ§Ã£o** transforma esse valor. Algumas que vocÃª viu:

* **Degrau (Step)**: retorna 0 ou 1 (ativa ou nÃ£o ativa).
* **Linear**: retorna o valor original do somatÃ³rio.
* **ReLU**: retorna 0 para valores negativos e o prÃ³prio valor se positivo. Muito usada em visÃ£o computacional.

---

## ğŸ§  Parte 4: Redes Neurais Multicamadas (MLP)

VocÃª foi alÃ©m do perceptron e entendeu o funcionamento das **redes neurais multicamadas** (Multilayer Perceptron â€“ MLP).

### ğŸ§± Como funciona?

* VÃ¡rias **camadas de neurÃ´nios** (entrada, ocultas e saÃ­da).
* Cada camada recebe os dados da anterior e **processa de forma mais especializada**.
* Essa estrutura permite que a rede **aprenda padrÃµes mais complexos**, como imagens, sons, ou relaÃ§Ãµes nÃ£o-lineares entre dados.

---

## â— Parte 5: O Exemplo do â€œOU-Exclusivoâ€ (XOR)

Um Ã³timo exemplo para demonstrar o poder das redes neurais foi o do **OU-Exclusivo (XOR)**, uma operaÃ§Ã£o lÃ³gica que **nÃ£o Ã© linearmente separÃ¡vel**.

### ğŸ§© Por que isso Ã© importante?

* Algoritmos simples, como **regressÃ£o logÃ­stica**, nÃ£o conseguem separar os dados de um problema XOR com uma Ãºnica reta.
* PorÃ©m, com **duas camadas de neurÃ´nios**, Ã© possÃ­vel representar a saÃ­da correta combinando mÃºltiplas "retas" (decisÃµes).

### ğŸ¯ Estrutura para resolver XOR:

1. Dois neurÃ´nios na primeira camada simulando as operaÃ§Ãµes â€œEâ€ e â€œOUâ€.
2. Um terceiro neurÃ´nio (segunda camada) combinando os resultados dos anteriores.
3. O resultado final identifica corretamente os casos em que **apenas uma entrada Ã© verdadeira**, ou seja, resolve o problema do XOR.

Este exemplo mostra como redes neurais conseguem **representar relaÃ§Ãµes nÃ£o lineares**, algo que muitos algoritmos clÃ¡ssicos nÃ£o conseguem.

---

## ğŸ§ª O que vem a seguir?

No prÃ³ximo passo, vocÃª irÃ¡ comeÃ§ar a **implementar redes neurais** usando bibliotecas como o **Scikit-learn**, explorando como colocar tudo isso em prÃ¡tica com cÃ³digo.

---
